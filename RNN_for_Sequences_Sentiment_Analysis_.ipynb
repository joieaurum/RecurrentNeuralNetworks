{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joieaurum/RecurrentNeuralNetworks/blob/main/RNN_for_Sequences_Sentiment_Analysis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFaTbFyUlX0E"
      },
      "source": [
        "## Introduction\n",
        "*Natural language Processing  \n",
        "*Look at this in a very simple manner either positive or negative and since its that then its a binary classification problem  \n",
        "-Sequence to sequence-encoder RNN-time series, text in sentences  \n",
        "-Recurrent because the network contains loops  \n",
        "-output of a given layer is an input to the same layer time step  \n",
        "-Time step ->time series, next word in a sequence of words text sequence  \n",
        "-RNN is attractive cause of the loops, which help them manage relationships"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5vk6LeqrarF"
      },
      "source": [
        "-In this example i will use the Long Short Term Memory(LSTM) layer->this is  \n",
        "-what makes the network recurrent\n",
        "it is optimized to learning sequences like predicting text input-chatbot,interlanguage translation,automated video closed caption'Speech recognition',speech synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ykYj_sTsLtr"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23wRZkk3rZlw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs6YD0tesVfv"
      },
      "outputs": [],
      "source": [
        "number_of_words=10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfTQkekbtCrG"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQqCMEwRuEqT"
      },
      "source": [
        "### modifying the default parameters of np.load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkT2M0HRttlX"
      },
      "outputs": [],
      "source": [
        "# save np.load\n",
        "np_load_old = np.load\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63qoPW9xvYMk"
      },
      "outputs": [],
      "source": [
        "# modify the default parameters of np.load\n",
        "np.load=lambda *a,**k:np_load_old(*a,allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_PBi1VJxckb",
        "outputId": "88c79fc9-5c0a-40f6-d124-ee573e3fa129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# call load_data with allow_pickle implicitly set to true\n",
        "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=number_of_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Uc7Y4AWxhUk"
      },
      "outputs": [],
      "source": [
        "# restore np.load for future normal usage\n",
        "np.load = np_load_old"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y7GXoBNyynn"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9rCqs5-yMC2",
        "outputId": "2edd06be-dddc-420e-964d-53e5eb1a10d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azGuyOhHy6L1",
        "outputId": "5b3c02a4-6028-4516-d86f-321cf7a9e128"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRyGBlDUy_Pi",
        "outputId": "7ebcf8e1-84cc-40c8-9ad9-d06221dee421"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItREQpWVzA_V",
        "outputId": "bc1d8322-e6c3-4141-8153-bf3d887f2b57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RQXgQ4VzbAX"
      },
      "source": [
        "-The arrays y_train and y_test -1 D,1s(positive) and 0s(negative)  \n",
        "-The X_test and X_train are a list of integers that represent the viewers comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpAHzZ-Xz194",
        "outputId": "6b5de9ee-b0a0-4ac5-c57c-663b78b4ab63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretty printing has been turned OFF\n"
          ]
        }
      ],
      "source": [
        "%pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBZ_zLg1zEF9",
        "outputId": "74417a03-5d25-4387-d5e4-00ad1b25e88b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Fk-pJ-z7QZ",
        "outputId": "0eda5fe4-ec96-4e14-b87c-61a26fab4b52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P09NeWc-0P81"
      },
      "source": [
        "Review the encodings  \n",
        "movies are numerically encoded,,text-word which each number corresponds to.  \n",
        "Keras IMDB dictionary maps words to their indices  \n",
        "Each word's value is its frequency ranking among the words in the dataset  \n",
        "1->is the most frequent word  \n",
        "offset by 3- training and trsting samples = 4 -0,1,2-reserved\n",
        "0-padding -dimensions 0000000 i do not like it  \n",
        "1-Start of the sequence - a token that keras uses for learning purposes 2-not loaded-unknown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSps03Og0KHy",
        "outputId": "1d3da229-9b80-43f1-9d82-fa7ea94ab101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "word_to_index=imdb.get_word_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXMiyRs91vih",
        "outputId": "9d793df6-e238-45b2-fddc-88835f52e5ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_to_index['the']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tzyyp_21yZH",
        "outputId": "dde7f8e9-d3f8-48e8-dff4-0dc81b6b3598"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_to_index['good']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMdG9MB42GX-"
      },
      "source": [
        "### Reverse word_to_index mapping "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkFoKukS14zg"
      },
      "outputs": [],
      "source": [
        "index_to_word={index:word for(word,index) in word_to_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnXP6FJj2UZS",
        "outputId": "70895f2e-33b0-4782-9f37-57cf0a7968b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the', 'and', 'a', 'of', 'to', 'is', 'br', 'in', 'it', 'i', 'this', 'that', 'was', 'as', 'for', 'with', 'movie', 'but', 'film', 'on', 'not', 'you', 'are', 'his', 'have', 'he', 'be', 'one', 'all', 'at', 'by', 'an', 'they', 'who', 'so', 'from', 'like', 'her', 'or', 'just', 'about', \"it's\", 'out', 'has', 'if', 'some', 'there', 'what', 'good', 'more']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[index_to_word[i] for i in range(1,51)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQpYAKAo2oqY"
      },
      "source": [
        "### Decode a Movie Review  \n",
        "- i->3 accounts for the offsets,0-2-? use the key to return thr value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_PUXZ112bAX",
        "outputId": "dc8038d9-2d4f-4076-f1a5-2b900b10daaa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"? worst mistake of my life br br i picked this movie up at target for 5 because i figured hey it's sandler i can get some cheap laughs i was wrong completely wrong mid way through the film all three of my friends were asleep and i was still suffering worst plot worst script worst movie i have ever seen i wanted to hit my head up against a wall for an hour then i'd stop and you know why because it felt damn good upon bashing my head in i stuck that damn movie in the ? and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\""
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "' '.join([index_to_word.get(i-3,'?')for i in X_train[4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdnxr6UQ3rmc",
        "outputId": "034db74f-6824-4240-e2c8-d7e14a54e489"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux2yFnQV5AQW"
      },
      "source": [
        "## Data Preparation\n",
        "-review varies  \n",
        "-same dimensions  \n",
        "-prepare data for learning -number of words,truncate few pad 0\n",
        "-pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXwU_Zmo39Nj"
      },
      "outputs": [],
      "source": [
        "words_per_review=200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfedZSZ65Xrf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8-wxNoH5faF"
      },
      "outputs": [],
      "source": [
        "X_train=pad_sequences(X_train,maxlen=words_per_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st-mbtZl5rhR",
        "outputId": "f85cf945-3e32-4041-df82-55bc57e5a5f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5FylkgN5tHR"
      },
      "outputs": [],
      "source": [
        "X_test=pad_sequences(X_test,maxlen=words_per_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkPNY7o_56Ld",
        "outputId": "72c40594-95fb-4bfa-c3a4-2a3970485773"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw6GqJ5E6JSd"
      },
      "source": [
        "## Split the data\n",
        "test and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ksoM19b58Au"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KaYp4iM6ae5"
      },
      "outputs": [],
      "source": [
        "X_test,X_val,y_test,y_val=train_test_split(X_test,y_test,random_state=11,test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn5OCZLO7Hng",
        "outputId": "ce2454aa-5988-446e-8ddb-944901c03ac0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20000, 200)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI8RG7iD7OFK",
        "outputId": "30dff8e2-4fd6-4107-e655-a4efe5f55bc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5000, 200)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kRy-x6M7goA"
      },
      "source": [
        "## Creating the Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6G_PDJ2jBLU"
      },
      "source": [
        "- Sequential model,then import the other layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJv8houj7PgA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUZ4fnYhjMuu"
      },
      "outputs": [],
      "source": [
        "rnn=Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YPux_MOjTSe",
        "outputId": "8b226827-0949-42a9-91e4-e3be2d1e691e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential object at 0x7fe0544d2a50>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70qwYW7cjUFQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense,LSTM,Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xpV97bijgmD"
      },
      "source": [
        "## Embedding\n",
        "-Adding an Embedding layer - In the CNN we used one hot encoding (converting MNIST into Categorical), each label then became a vector 9(0 0 0 0 0 0 0 0 0 1)  \n",
        "- We can do the same for index values that represent words for example for 'the' the value data(1 0 0)  \n",
        "- This becomes problematic with a large number of words  \n",
        "- To solve this problem we begin with an Embedding layer to reduce dimensionality  \n",
        "-This encodes each word in a more compact dense-vector representation.  \n",
        "-The idea is to capture the words' context  \n",
        "-RNN learns word relationships  \n",
        "- There are very popular word embeddings- Word2Vec and Glove, and you can use them to load neural network and this will save you time, its also used to add basic word relationships to model smaller amount of training data, easy to improve model accuracy by building upon work that was done previously"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPLzhIIQjd59"
      },
      "outputs": [],
      "source": [
        "rnn.add(Embedding(input_dim=number_of_words,output_dim=128,input_length=words_per_review))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkoGoEAhmeMk"
      },
      "source": [
        "### Adding a LSTM layer\n",
        "-Number of neurons- more neurons means network can remember more"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAYniwxLmP0-"
      },
      "outputs": [],
      "source": [
        "rnn.add(LSTM(units=128, dropout=0.2,recurrent_dropout=0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbZ7_XT_nzGi"
      },
      "source": [
        "### Adding a Dense Output layer\n",
        "-To be able to reduce the output to one result-0 or 1-negative or positive  \n",
        "-This is where we use the activation function; sigmoid function: best for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enHSOOT_nv1-"
      },
      "outputs": [],
      "source": [
        "rnn.add(Dense(units=1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-zqqqhMoY1T"
      },
      "source": [
        "## Compile the model and display the summary\n",
        "- Binary crossentropy as a loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sND4gEDDoPOO"
      },
      "outputs": [],
      "source": [
        "rnn.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSPAjFhfozAy",
        "outputId": "360ce56d-685b-4175-b5bf-b0bb82ac5534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,411,713\n",
            "Trainable params: 1,411,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "rnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEA029aoqopi"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqBQNb8Sq6VT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJzi2ECLo9Zr",
        "outputId": "c3536e2d-4f00-4943-8c9d-459ab424d037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 516s 656ms/step - loss: 0.4741 - accuracy: 0.7756 - val_loss: 0.4077 - val_accuracy: 0.8404\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 513s 656ms/step - loss: 0.2934 - accuracy: 0.8802 - val_loss: 0.3237 - val_accuracy: 0.8670\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 511s 653ms/step - loss: 0.1971 - accuracy: 0.9242 - val_loss: 0.3950 - val_accuracy: 0.8645\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 503s 643ms/step - loss: 0.1512 - accuracy: 0.9438 - val_loss: 0.3625 - val_accuracy: 0.8504\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 508s 650ms/step - loss: 0.2913 - accuracy: 0.8788 - val_loss: 0.3615 - val_accuracy: 0.8629\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 506s 648ms/step - loss: 0.1327 - accuracy: 0.9513 - val_loss: 0.3917 - val_accuracy: 0.8655\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 506s 647ms/step - loss: 0.0871 - accuracy: 0.9694 - val_loss: 0.4638 - val_accuracy: 0.8617\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 507s 649ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.6273 - val_accuracy: 0.8584\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 506s 647ms/step - loss: 0.0455 - accuracy: 0.9852 - val_loss: 0.5301 - val_accuracy: 0.8456\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 506s 647ms/step - loss: 0.0413 - accuracy: 0.9863 - val_loss: 0.5828 - val_accuracy: 0.8578\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History object at 0x7fe05a41e0d0>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn.fit(X_train,y_train,epochs=10,batch_size=32, validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4ptT1x42vJc"
      },
      "source": [
        "## Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjlmVgdP2r0b"
      },
      "outputs": [],
      "source": [
        "results= rnn.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uluj4IiT3nOv",
        "outputId": "bc22dba8-2151-49fa-e2b3-3784323095fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.5828183889389038, 0.8578000068664551]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLbZ82l1CrDY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "WMdG9MB42GX-",
        "NQpYAKAo2oqY"
      ],
      "name": "RNN for Sequences: Sentiment Analysis .ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOmq3GuwBKsdARrEVNrYaSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}